#!/bin/bash
# Kubernetes + å¤šæ§åˆ¶å°é€‰æ‹©å®‰è£…è„šæœ¬ - æ”¯æŒ Ubuntu/Debian/CentOS/RHEL
set -e

echo "ğŸš€ Kubernetes + å¤šæ§åˆ¶å°é€‰æ‹©å®‰è£…è„šæœ¬ v6.1 (ç½‘ç»œä¿®å¤ç‰ˆ)"
echo "æ”¯æŒ Ubuntu/Debian/CentOS/RHEL ç³»ç»Ÿ - å¼ºåˆ¶æ¸…ç†é‡è£…"

# æ£€æŸ¥æ˜¯å¦ä¸º root ç”¨æˆ·
if [[ $EUID -ne 0 ]]; then
   echo "âŒ æ­¤è„šæœ¬éœ€è¦ root æƒé™è¿è¡Œ"
   echo "è¯·ä½¿ç”¨: sudo $0"
   exit 1
fi

# æ£€æµ‹ç³»ç»Ÿç±»å‹
detect_os() {
    if [ -f /etc/os-release ]; then
        . /etc/os-release
        OS=$ID
        OS_VERSION=$VERSION_ID
        
        # ç‰¹åˆ«å¤„ç†ä¸€äº›ç³»ç»Ÿçš„è¯†åˆ«
        case $ID in
            ubuntu)
                OS="ubuntu"
                CODENAME=$VERSION_CODENAME
                ;;
            debian)
                OS="debian" 
                CODENAME=$VERSION_CODENAME
                ;;
            centos|rhel|rocky|almalinux)
                OS=$ID
                ;;
            *)
                # å¦‚æœæ£€æµ‹ä¸åˆ°ï¼Œé€šè¿‡æ–‡ä»¶åˆ¤æ–­
                if [ -f /etc/debian_version ]; then
                    if grep -q "ubuntu" /etc/os-release 2>/dev/null; then
                        OS="ubuntu"
                    else
                        OS="debian"
                    fi
                    CODENAME=$(lsb_release -cs 2>/dev/null || echo "bullseye")
                elif [ -f /etc/redhat-release ]; then
                    OS="centos"
                fi
                ;;
        esac
    elif [ -f /etc/debian_version ]; then
        OS="debian"
        CODENAME=$(lsb_release -cs 2>/dev/null || echo "bullseye")
    elif [ -f /etc/redhat-release ]; then
        OS="centos"
        OS_VERSION=$(cat /etc/redhat-release | grep -oE '[0-9]+\.[0-9]+' | head -1)
    else
        echo "âŒ æ— æ³•æ£€æµ‹ç³»ç»Ÿç±»å‹"
        exit 1
    fi
    
    echo "æ£€æµ‹åˆ°ç³»ç»Ÿ: $OS"
    if [ -n "$OS_VERSION" ]; then
        echo "ç³»ç»Ÿç‰ˆæœ¬: $OS_VERSION"
    fi
    if [ -n "$CODENAME" ]; then
        echo "ä»£ç å: $CODENAME"
    fi
    
    # è®¾ç½®åŒ…ç®¡ç†å™¨
    case $OS in
        ubuntu|debian)
            PKG_MANAGER="apt"
            ;;
        centos|rhel|rocky|almalinux)
            PKG_MANAGER="yum"
            if command -v dnf >/dev/null 2>&1; then
                PKG_MANAGER="dnf"
            fi
            ;;
        *)
            echo "âŒ ä¸æ”¯æŒçš„ç³»ç»Ÿ: $OS"
            exit 1
            ;;
    esac
    
    echo "ä½¿ç”¨åŒ…ç®¡ç†å™¨: $PKG_MANAGER"
}

# å¼ºåˆ¶æ¸…ç†æ‰€æœ‰ Kubernetes ç›¸å…³ç»„ä»¶
force_cleanup() {
    echo ""
    echo "ğŸ§¹ [1/13] å¼ºåˆ¶æ¸…ç†æ‰€æœ‰ Kubernetes ç»„ä»¶..."
    
    # åœæ­¢ç›¸å…³æœåŠ¡ï¼ˆä¿ç•™ Dockerï¼‰
    echo "åœæ­¢ç›¸å…³æœåŠ¡..."
    systemctl stop kubelet 2>/dev/null || true
    systemctl stop containerd 2>/dev/null || true
    systemctl stop cri-docker 2>/dev/null || true
    
    # å¼ºåˆ¶æ€æ­»ç›¸å…³è¿›ç¨‹ï¼ˆä¿ç•™ Dockerï¼‰
    echo "æ€æ­»ç›¸å…³è¿›ç¨‹..."
    pkill -9 -f kubelet 2>/dev/null || true
    pkill -9 -f kube-proxy 2>/dev/null || true
    pkill -9 -f kube-apiserver 2>/dev/null || true
    pkill -9 -f kube-controller 2>/dev/null || true
    pkill -9 -f kube-scheduler 2>/dev/null || true
    pkill -9 -f etcd 2>/dev/null || true
    pkill -9 -f containerd 2>/dev/null || true
    # æ³¨æ„ï¼šä¸æ€æ­» dockerd è¿›ç¨‹ï¼Œä¿ç•™ Docker
    
    # ç­‰å¾…è¿›ç¨‹å®Œå…¨åœæ­¢
    sleep 5
    
    # é‡ç½® kubeadmï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    echo "é‡ç½® kubeadm..."
    kubeadm reset -f 2>/dev/null || true
    
    # å¸è½½è½¯ä»¶åŒ…ï¼ˆä¿ç•™ Dockerï¼‰
    echo "å¸è½½ Kubernetes ç›¸å…³è½¯ä»¶åŒ…..."
    case $PKG_MANAGER in
        apt)
            apt-mark unhold kubelet kubeadm kubectl 2>/dev/null || true
            apt remove --purge -y kubelet kubeadm kubectl kubernetes-cni 2>/dev/null || true
            apt remove --purge -y containerd.io containerd 2>/dev/null || true
            apt remove --purge -y cri-tools 2>/dev/null || true
            # æ³¨æ„ï¼šä¸å¸è½½ Docker ç›¸å…³åŒ…
            # apt remove --purge -y docker-ce docker-ce-cli docker-buildx-plugin docker-compose-plugin
            apt autoremove -y 2>/dev/null || true
            apt autoclean 2>/dev/null || true
            ;;
        yum|dnf)
            $PKG_MANAGER remove -y kubelet kubeadm kubectl kubernetes-cni 2>/dev/null || true
            $PKG_MANAGER remove -y containerd.io containerd 2>/dev/null || true
            $PKG_MANAGER remove -y cri-tools 2>/dev/null || true
            # æ³¨æ„ï¼šä¸å¸è½½ Docker ç›¸å…³åŒ…
            # $PKG_MANAGER remove -y docker-ce docker-ce-cli
            $PKG_MANAGER autoremove -y 2>/dev/null || true
            ;;
    esac
    
    # æ¸…ç†æ–‡ä»¶å’Œç›®å½•ï¼ˆä¿ç•™ Docker æ•°æ®ï¼‰
    echo "æ¸…ç†æ–‡ä»¶å’Œç›®å½•..."
    rm -rf ~/.kube
    rm -rf /etc/kubernetes
    rm -rf /var/lib/kubelet
    rm -rf /var/lib/etcd
    rm -rf /etc/containerd
    rm -rf /var/lib/containerd
    rm -rf /opt/containerd
    # æ³¨æ„ï¼šä¿ç•™ Docker ç›®å½•
    # rm -rf /etc/docker
    # rm -rf /var/lib/docker
    rm -rf /opt/cni
    rm -rf /etc/cni
    rm -rf /var/lib/cni
    rm -rf /run/flannel
    rm -rf /etc/systemd/system/kubelet.service.d
    # æ³¨æ„ï¼šä¿ç•™ Docker systemd é…ç½®
    # rm -rf /etc/systemd/system/docker.service.d
    rm -rf /lib/systemd/system/kubelet.service
    rm -rf /etc/crictl.yaml
    
    # æ¸…ç†ä»“åº“é…ç½®ï¼ˆä¿ç•™ Docker ä»“åº“ï¼‰
    echo "æ¸…ç†ä»“åº“é…ç½®..."
    rm -rf /etc/apt/sources.list.d/kubernetes*.list
    rm -rf /etc/yum.repos.d/kubernetes.repo
    rm -rf /etc/apt/keyrings/kubernetes*.gpg
    # æ³¨æ„ï¼šä¿ç•™ Docker ä»“åº“é…ç½®
    # rm -rf /etc/apt/sources.list.d/docker*.list
    # rm -rf /etc/yum.repos.d/docker*.repo
    # rm -rf /etc/apt/keyrings/docker*.gpg
    
    # æ¸…ç†ç½‘ç»œæ¥å£
    echo "æ¸…ç†ç½‘ç»œæ¥å£..."
    ip link delete cni0 2>/dev/null || true
    ip link delete flannel.1 2>/dev/null || true
    ip link delete kube-bridge 2>/dev/null || true
    # æ³¨æ„ï¼šä¿ç•™ docker0 ç½‘æ¡¥
    # ip link delete docker0 2>/dev/null || true
    
    # æ¸…ç† iptables è§„åˆ™ï¼ˆåªæ¸…ç† Kubernetes ç›¸å…³ï¼‰
    echo "æ¸…ç† Kubernetes iptables è§„åˆ™..."
    # æ¸…ç† Kubernetes ç›¸å…³çš„ iptables è§„åˆ™ï¼Œä½†ä¿ç•™ Docker è§„åˆ™
    iptables-save | grep -v KUBE | iptables-restore 2>/dev/null || {
        # å¦‚æœä¸Šé¢çš„æ–¹æ³•å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•ä½†æ›´å°å¿ƒ
        iptables -t filter -D FORWARD -j DOCKER-USER 2>/dev/null || true
        iptables -t filter -D FORWARD -j DOCKER-ISOLATION-STAGE-1 2>/dev/null || true
        # æ¸…ç†å…¶ä»–é Docker è§„åˆ™
        iptables -F INPUT 2>/dev/null || true
        iptables -F OUTPUT 2>/dev/null || true
        iptables -t nat -F OUTPUT 2>/dev/null || true
        iptables -t nat -F PREROUTING 2>/dev/null || true
    }
    
    # æ¸…ç† systemd æœåŠ¡
    echo "æ¸…ç† systemd æœåŠ¡..."
    systemctl daemon-reload
    systemctl reset-failed
    
    # å¼ºåˆ¶å¸è½½æ®‹ç•™çš„æŒ‚è½½ç‚¹
    echo "æ¸…ç†æŒ‚è½½ç‚¹..."
    umount /var/lib/kubelet/pods/*/volumes/kubernetes.io~secret/* 2>/dev/null || true
    umount /var/lib/kubelet/pods/*/volumes/kubernetes.io~configmap/* 2>/dev/null || true
    umount /var/lib/kubelet/* 2>/dev/null || true
    
    # æ£€æŸ¥å¹¶æ€æ­»å ç”¨ Kubernetes å…³é”®ç«¯å£çš„è¿›ç¨‹ï¼ˆä¸å½±å“ Dockerï¼‰
    echo "æ£€æŸ¥ Kubernetes å…³é”®ç«¯å£..."
    for port in 6443 10250 10251 10252 2379 2380; do
        PID=$(lsof -ti :$port 2>/dev/null || true)
        if [ -n "$PID" ]; then
            echo "æ€æ­»å ç”¨ç«¯å£ $port çš„è¿›ç¨‹ $PID"
            kill -9 $PID 2>/dev/null || true
        fi
    done
    
    echo "âœ… Kubernetes ç»„ä»¶æ¸…ç†å®Œæˆï¼ˆDocker å·²ä¿ç•™ï¼‰"
}

# æ›´æ–°ç³»ç»Ÿå‡½æ•°
update_system() {
    case $PKG_MANAGER in
        apt)
            apt update
            ;;
        yum|dnf)
            $PKG_MANAGER update -y
            ;;
    esac
}

# å®‰è£…åŸºç¡€åŒ…å‡½æ•°
install_basic_packages() {
    case $PKG_MANAGER in
        apt)
            apt install -y apt-transport-https ca-certificates curl gnupg lsb-release software-properties-common wget
            ;;
        yum|dnf)
            $PKG_MANAGER install -y curl gnupg2 software-properties-common yum-utils device-mapper-persistent-data lvm2 wget
            ;;
    esac
}

# å®‰è£… containerd å‡½æ•°
install_containerd() {
    case $OS in
        ubuntu)
            # Ubuntu
            mkdir -p /etc/apt/keyrings
            curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /etc/apt/keyrings/docker.gpg
            echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | tee /etc/apt/sources.list.d/docker.list > /dev/null
            apt update
            apt install -y containerd.io
            ;;
        debian)
            # Debian
            mkdir -p /etc/apt/keyrings
            curl -fsSL https://download.docker.com/linux/debian/gpg | gpg --dearmor -o /etc/apt/keyrings/docker.gpg
            echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/debian $(lsb_release -cs) stable" | tee /etc/apt/sources.list.d/docker.list > /dev/null
            apt update
            apt install -y containerd.io
            ;;
        centos|rhel|rocky|almalinux)
            # CentOS/RHEL
            $PKG_MANAGER config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
            $PKG_MANAGER install -y containerd.io
            ;;
    esac
}

# å®‰è£… Kubernetes å‡½æ•°
install_kubernetes() {
    case $PKG_MANAGER in
        apt)
            # Ubuntu/Debian
            curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.29/deb/Release.key | gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
            echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.29/deb/ /' | tee /etc/apt/sources.list.d/kubernetes.list
            apt update
            apt install -y kubelet=1.29.0-1.1 kubeadm=1.29.0-1.1 kubectl=1.29.0-1.1
            apt-mark hold kubelet kubeadm kubectl
            ;;
        yum|dnf)
            # CentOS/RHEL
            cat <<EOF | tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://pkgs.k8s.io/core:/stable:/v1.29/rpm/
enabled=1
gpgcheck=1
gpgkey=https://pkgs.k8s.io/core:/stable:/v1.29/rpm/repodata/repomd.xml.key
EOF
            $PKG_MANAGER install -y kubelet-1.29.0 kubeadm-1.29.0 kubectl-1.29.0 --disableexcludes=kubernetes
            ;;
    esac
}

# å®‰è£… Helm
install_helm() {
    echo "å®‰è£… Helm..."
    if ! command -v helm &> /dev/null; then
        curl https://get.helm.sh/helm-v3.12.1-linux-amd64.tar.gz -o helm.tar.gz
        tar -zxvf helm.tar.gz
        mv linux-amd64/helm /usr/local/bin/helm
        rm -rf helm.tar.gz linux-amd64
        chmod +x /usr/local/bin/helm
    fi
    helm version
}

# é€‰æ‹©æ§åˆ¶å°ç±»å‹
choose_dashboard() {
    echo ""
    echo "ğŸ¯ é€‰æ‹©è¦å®‰è£…çš„æ§åˆ¶å°ï¼š"
    echo "1) Kubernetes Dashboard (å®˜æ–¹ï¼Œè½»é‡çº§ï¼ŒToken ç™»å½•)"
    echo "2) Rancher (å¼€æºç‰ˆï¼ŒåŠŸèƒ½å®Œæ•´ï¼Œå›¾å½¢åŒ–ç”¨æˆ·ç®¡ç†)"
    echo "3) KubeSphere (ç°ä»£åŒ–ç•Œé¢ï¼ŒåŠŸèƒ½ä¸°å¯Œï¼Œä¸­æ–‡æ”¯æŒ)"
    echo ""
    while true; do
        read -p "è¯·é€‰æ‹© [1-3]: " DASHBOARD_CHOICE
        case $DASHBOARD_CHOICE in
            1)
                INSTALL_K8S_DASHBOARD=true
                INSTALL_RANCHER=false
                INSTALL_KUBESPHERE=false
                echo "âœ… å·²é€‰æ‹©ï¼šKubernetes Dashboard"
                break
                ;;
            2)
                INSTALL_K8S_DASHBOARD=false
                INSTALL_RANCHER=true
                INSTALL_KUBESPHERE=false
                echo "âœ… å·²é€‰æ‹©ï¼šRancher"
                break
                ;;
            3)
                INSTALL_K8S_DASHBOARD=false
                INSTALL_RANCHER=false
                INSTALL_KUBESPHERE=true
                echo "âœ… å·²é€‰æ‹©ï¼šKubeSphere"
                break
                ;;
            *)
                echo "âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1ã€2 æˆ– 3"
                ;;
        esac
    done
}

# å¼€å§‹å®‰è£…
detect_os

echo ""
echo "ğŸ“‹ ç³»ç»Ÿä¿¡æ¯ï¼š"
echo "æ“ä½œç³»ç»Ÿ: $OS $OS_VERSION"
echo "åŒ…ç®¡ç†å™¨: $PKG_MANAGER"
if [ -n "$CODENAME" ]; then
    echo "ä»£ç å: $CODENAME"
fi

# é€‰æ‹©æ§åˆ¶å°
choose_dashboard

# å¼ºåˆ¶æ¸…ç†
force_cleanup

echo ""
echo "ğŸ“¦ [2/13] æ›´æ–°ç³»ç»Ÿå¹¶å®‰è£…ä¾èµ–..."
update_system
install_basic_packages

echo ""
echo "ğŸ”§ [3/13] é…ç½®å†…æ ¸å‚æ•°..."
# é…ç½®å†…æ ¸æ¨¡å—
cat <<EOF | tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF

modprobe overlay
modprobe br_netfilter

# é…ç½®ç³»ç»Ÿå‚æ•°
cat <<EOF | tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF

sysctl --system

# ç¦ç”¨ SELinux (å¯¹äº RHEL/CentOS)
if [ "$OS" = "centos" ] || [ "$OS" = "rhel" ] || [ "$OS" = "rocky" ] || [ "$OS" = "almalinux" ]; then
    setenforce 0 2>/dev/null || true
    sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config 2>/dev/null || true
fi

# ç¦ç”¨ swap
swapoff -a
sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab

echo ""
echo "ğŸ³ [4/13] å®‰è£… containerd..."
install_containerd

echo ""
echo "ğŸ”§ [5/13] é…ç½® containerd..."

# åœæ­¢ containerd æœåŠ¡
systemctl stop containerd 2>/dev/null || true

# åˆ›å»ºé…ç½®ç›®å½•
mkdir -p /etc/containerd

# ç”Ÿæˆé»˜è®¤é…ç½®
containerd config default > /etc/containerd/config.toml

# ä¿®æ”¹é…ç½®æ–‡ä»¶ä»¥å¯ç”¨ systemd cgroup å’Œ CRI
sed -i 's/SystemdCgroup = false/SystemdCgroup = true/' /etc/containerd/config.toml

# ç¡®ä¿ CRI æ’ä»¶æœªè¢«ç¦ç”¨
sed -i '/disabled_plugins.*cri/d' /etc/containerd/config.toml

# å¯åŠ¨ containerd
systemctl daemon-reload
systemctl enable containerd
systemctl start containerd

# ç­‰å¾…æœåŠ¡å¯åŠ¨
sleep 10

echo "éªŒè¯ containerd çŠ¶æ€:"
systemctl status containerd --no-pager

echo ""
echo "â˜¸ï¸  [6/13] å®‰è£… Kubernetes 1.29..."
install_kubernetes

# å¯åŠ¨ kubelet
systemctl enable kubelet

echo ""
echo "ğŸ”§ [7/13] é…ç½® CRI æ¥å£..."

# å®‰è£… cri-tools
case $PKG_MANAGER in
    apt)
        apt install -y cri-tools
        ;;
    yum|dnf)
        $PKG_MANAGER install -y cri-tools
        ;;
esac

# é…ç½® crictl
cat > /etc/crictl.yaml << EOF
runtime-endpoint: unix:///var/run/containerd/containerd.sock
image-endpoint: unix:///var/run/containerd/containerd.sock
timeout: 10
debug: false
pull-image-on-create: false
EOF

echo ""
echo "ğŸ› ï¸ [8/13] å®‰è£… Helm..."
install_helm

echo ""
echo "ğŸ” [9/13] éªŒè¯å®‰è£…..."

echo "containerd ç‰ˆæœ¬:"
containerd --version

echo "crictl ç‰ˆæœ¬:"
crictl version

echo "kubeadm ç‰ˆæœ¬:"
kubeadm version

echo "kubelet ç‰ˆæœ¬:"
kubelet --version

echo "kubectl ç‰ˆæœ¬:"
kubectl version --client

echo "helm ç‰ˆæœ¬:"
helm version

# æµ‹è¯• CRI è¿æ¥
echo "æµ‹è¯• CRI è¿æ¥:"
crictl info | head -20

echo ""
echo "ğŸ¯ [10/13] åˆå§‹åŒ– Kubernetes é›†ç¾¤..."

# è·å–æœ¬æœº IP
LOCAL_IP=$(hostname -I | awk '{print $1}')
echo "ä½¿ç”¨ IP åœ°å€: $LOCAL_IP"

# æ‹‰å–å¿…è¦çš„é•œåƒ
echo "é¢„æ‹‰å– Kubernetes é•œåƒ..."
kubeadm config images pull --cri-socket unix:///var/run/containerd/containerd.sock

# åˆå§‹åŒ–é›†ç¾¤
echo "æ­£åœ¨åˆå§‹åŒ–é›†ç¾¤..."
kubeadm init \
    --apiserver-advertise-address=$LOCAL_IP \
    --pod-network-cidr=10.244.0.0/16 \
    --service-cidr=10.96.0.0/12 \
    --cri-socket=unix:///var/run/containerd/containerd.sock \
    --kubernetes-version=v1.29.0 \
    --ignore-preflight-errors=Port-6443,Port-10250,Port-10251,Port-10252,Port-2379,Port-2380

# é…ç½® kubectl
mkdir -p $HOME/.kube
cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
chown $(id -u):$(id -g) $HOME/.kube/config

# ç§»é™¤ master æ±¡ç‚¹
kubectl taint nodes --all node-role.kubernetes.io/control-plane- 2>/dev/null || true

echo ""
echo "ğŸŒ [11/13] å®‰è£…ç½‘ç»œæ’ä»¶..."

# åœæ­¢ kubelet ä»¥ç¡®ä¿å¹²å‡€çš„ç½‘ç»œè®¾ç½®
systemctl stop kubelet

# æ¸…ç†å¯èƒ½å­˜åœ¨çš„ç½‘ç»œé…ç½®
echo "æ¸…ç†ç°æœ‰ç½‘ç»œé…ç½®..."
rm -rf /etc/cni/net.d/*
rm -rf /var/lib/cni/*
rm -rf /run/flannel/*
ip link delete cni0 2>/dev/null || true
ip link delete flannel.1 2>/dev/null || true

# åˆ›å»ºå¿…è¦çš„ç›®å½•
mkdir -p /run/flannel
mkdir -p /etc/cni/net.d
mkdir -p /opt/cni/bin

# é‡å¯ kubelet
systemctl start kubelet
sleep 10

# ä½¿ç”¨ç¨³å®šçš„ Flannel é…ç½®
echo "å®‰è£…ä¼˜åŒ–çš„ Flannel ç½‘ç»œæ’ä»¶..."
cat <<EOF | kubectl apply -f -
---
apiVersion: v1
kind: Namespace
metadata:
  labels:
    k8s-app: flannel
    pod-security.kubernetes.io/enforce: privileged
  name: kube-flannel
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    k8s-app: flannel
  name: flannel
  namespace: kube-flannel
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    k8s-app: flannel
  name: flannel
rules:
- apiGroups:
  - ""
  resources:
  - pods
  verbs:
  - get
- apiGroups:
  - ""
  resources:
  - nodes
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - nodes/status
  verbs:
  - patch
- apiGroups:
  - networking.k8s.io
  resources:
  - clustercidrs
  verbs:
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    k8s-app: flannel
  name: flannel
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: flannel
subjects:
- kind: ServiceAccount
  name: flannel
  namespace: kube-flannel
---
apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    app: flannel
    k8s-app: flannel
    tier: node
  name: kube-flannel-cfg
  namespace: kube-flannel
data:
  cni-conf.json: |
    {
      "name": "cbr0",
      "cniVersion": "1.0.0",
      "plugins": [
        {
          "type": "flannel",
          "delegate": {
            "hairpinMode": true,
            "isDefaultGateway": true
          }
        },
        {
          "type": "portmap",
          "capabilities": {
            "portMappings": true
          }
        }
      ]
    }
  net-conf.json: |
    {
      "Network": "10.244.0.0/16",
      "Backend": {
        "Type": "vxlan"
      }
    }
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  labels:
    app: flannel
    k8s-app: flannel
    tier: node
  name: kube-flannel-ds
  namespace: kube-flannel
spec:
  selector:
    matchLabels:
      app: flannel
      k8s-app: flannel
  template:
    metadata:
      labels:
        app: flannel
        k8s-app: flannel
        tier: node
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: kubernetes.io/os
                operator: In
                values:
                - linux
      containers:
      - args:
        - --ip-masq
        - --kube-subnet-mgr
        command:
        - /opt/bin/flanneld
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: EVENT_QUEUE_DEPTH
          value: "5000"
        image: docker.io/flannel/flannel:v0.24.2
        name: kube-flannel
        resources:
          requests:
            cpu: 100m
            memory: 50Mi
        securityContext:
          capabilities:
            add:
            - NET_ADMIN
            - NET_RAW
          privileged: false
        volumeMounts:
        - mountPath: /run/flannel
          name: run
        - mountPath: /etc/kube-flannel/
          name: flannel-cfg
        - mountPath: /run/xtables.lock
          name: xtables-lock
      hostNetwork: true
      initContainers:
      - args:
        - -f
        - /flannel
        - /opt/cni/bin/flannel
        command:
        - cp
        image: docker.io/flannel/flannel-cni-plugin:v1.4.0-flannel1
        name: install-cni-plugin
        volumeMounts:
        - mountPath: /opt/cni/bin
          name: cni-plugin
      - args:
        - -f
        - /etc/kube-flannel/cni-conf.json
        - /etc/cni/net.d/10-flannel.conflist
        command:
        - cp
        image: docker.io/flannel/flannel:v0.24.2
        name: install-cni
        volumeMounts:
        - mountPath: /etc/cni/net.d
          name: cni
        - mountPath: /etc/kube-flannel/
          name: flannel-cfg
      priorityClassName: system-node-critical
      serviceAccountName: flannel
      tolerations:
      - effect: NoSchedule
        operator: Exists
      volumes:
      - hostPath:
          path: /run/flannel
        name: run
      - hostPath:
          path: /opt/cni/bin
        name: cni-plugin
      - hostPath:
          path: /etc/cni/net.d
        name: cni
      - configMap:
          name: kube-flannel-cfg
        name: flannel-cfg
      - hostPath:
          path: /run/xtables.lock
          type: FileOrCreate
        name: xtables-lock
EOF

# ç­‰å¾… Flannel Pod å¯åŠ¨
echo "ç­‰å¾… Flannel Pod å¯åŠ¨ï¼ˆæœ€å¤š 5 åˆ†é’Ÿï¼‰..."
for i in {1..20}; do
    FLANNEL_STATUS=$(kubectl get pods -n kube-flannel --no-headers 2>/dev/null | grep -v Terminating | awk '{print $3}' | head -1)
    if [ "$FLANNEL_STATUS" = "Running" ]; then
        echo "âœ… Flannel å¯åŠ¨æˆåŠŸï¼"
        break
    elif [ "$FLANNEL_STATUS" = "CrashLoopBackOff" ] || [ "$FLANNEL_STATUS" = "Error" ]; then
        echo "âš ï¸ Flannel å¯åŠ¨å¤±è´¥ï¼ŒçŠ¶æ€: $FLANNEL_STATUS"
        echo "æŸ¥çœ‹è¯¦ç»†æ—¥å¿—:"
        kubectl logs -n kube-flannel -l app=flannel --tail=20 2>/dev/null || echo "æ—¥å¿—æš‚ä¸å¯ç”¨"
        
        # ä¿®å¤ Flannel ç›®å½•æƒé™
        echo "ä¿®å¤ Flannel ç›®å½•æƒé™..."
        mkdir -p /run/flannel
        chmod 755 /run/flannel
        
        # æ‰‹åŠ¨åˆ›å»º subnet.env æ–‡ä»¶
        echo "åˆ›å»º Flannel subnet.env æ–‡ä»¶..."
        cat > /run/flannel/subnet.env << SUBNETEOF
FLANNEL_NETWORK=10.244.0.0/16
FLANNEL_SUBNET=10.244.0.1/24
FLANNEL_MTU=1450
FLANNEL_IPMASQ=true
SUBNETEOF
        
        # é‡å¯ Flannel Pod
        kubectl delete pods -n kube-flannel --all 2>/dev/null || true
        sleep 30
        break
    else
        echo "ç­‰å¾…ä¸­... (${i}/20) å½“å‰çŠ¶æ€: ${FLANNEL_STATUS:-"åˆ›å»ºä¸­"}"
        sleep 15
    fi
done

# ç¡®ä¿ /run/flannel/subnet.env æ–‡ä»¶å­˜åœ¨
if [ ! -f /run/flannel/subnet.env ]; then
    echo "åˆ›å»º Flannel subnet.env æ–‡ä»¶..."
    mkdir -p /run/flannel
    cat > /run/flannel/subnet.env << EOF
FLANNEL_NETWORK=10.244.0.0/16
FLANNEL_SUBNET=10.244.0.1/24
FLANNEL_MTU=1450
FLANNEL_IPMASQ=true
EOF
    chmod 644 /run/flannel/subnet.env
fi

# ç­‰å¾…èŠ‚ç‚¹å°±ç»ª
echo "ç­‰å¾…èŠ‚ç‚¹å°±ç»ª..."
kubectl wait --for=condition=Ready node --all --timeout=300s || true

# æ£€æŸ¥ CoreDNS
echo "æ£€æŸ¥ CoreDNS çŠ¶æ€..."
kubectl wait --for=condition=available --timeout=180s deployment/coredns -n kube-system || true

# æœ€ç»ˆéªŒè¯
echo "éªŒè¯ç½‘ç»œé…ç½®..."
sleep 15
FLANNEL_FINAL=$(kubectl get pods -n kube-flannel --no-headers | grep Running | wc -l)
if [ "$FLANNEL_FINAL" -eq 0 ]; then
    echo "âš ï¸  Flannel ä»æœªæ­£å¸¸è¿è¡Œï¼Œä½†ç»§ç»­å®‰è£…..."
    echo "å¯ä»¥ç¨åæ‰‹åŠ¨ä¿®å¤ç½‘ç»œé—®é¢˜"
else
    echo "âœ… Flannel ç½‘ç»œé…ç½®å®Œæˆ"
fi

echo "âœ… ç½‘ç»œæ’ä»¶é…ç½®å®Œæˆ"

echo ""
echo "ğŸ“Š [12/13] å®‰è£…æ§åˆ¶å°..."

# å®‰è£… Kubernetes Dashboardï¼ˆå¦‚æœé€‰æ‹©ï¼‰
if [ "$INSTALL_K8S_DASHBOARD" = true ]; then
    echo "å®‰è£… Kubernetes Dashboard..."
    kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml || {
        echo "GitHub ä¸‹è½½å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹å¼..."
        # å¤‡ç”¨æ–¹å¼ï¼šå†…è”é…ç½®
        cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Namespace
metadata:
  name: kubernetes-dashboard
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard
  namespace: kubernetes-dashboard
---
kind: Service
apiVersion: v1
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard
  namespace: kubernetes-dashboard
spec:
  type: NodePort
  ports:
    - port: 443
      targetPort: 8443
      nodePort: 30443
  selector:
    k8s-app: kubernetes-dashboard
---
apiVersion: v1
kind: Secret
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard-certs
  namespace: kubernetes-dashboard
type: Opaque
---
apiVersion: v1
kind: Secret
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard-csrf
  namespace: kubernetes-dashboard
type: Opaque
data:
  csrf: ""
---
apiVersion: v1
kind: Secret
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard-key-holder
  namespace: kubernetes-dashboard
type: Opaque
---
kind: ConfigMap
apiVersion: v1
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard-settings
  namespace: kubernetes-dashboard
---
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard
  namespace: kubernetes-dashboard
rules:
  - apiGroups: [""]
    resources: ["secrets"]
    resourceNames: ["kubernetes-dashboard-key-holder", "kubernetes-dashboard-certs", "kubernetes-dashboard-csrf"]
    verbs: ["get", "update", "delete"]
  - apiGroups: [""]
    resources: ["configmaps"]
    resourceNames: ["kubernetes-dashboard-settings"]
    verbs: ["get", "update"]
  - apiGroups: [""]
    resources: ["services"]
    resourceNames: ["heapster", "dashboard-metrics-scraper"]
    verbs: ["proxy"]
  - apiGroups: [""]
    resources: ["services/proxy"]
    resourceNames: ["heapster", "http:heapster:", "https:heapster:", "dashboard-metrics-scraper", "http:dashboard-metrics-scraper"]
    verbs: ["get"]
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard
rules:
  - apiGroups: ["metrics.k8s.io"]
    resources: ["pods", "nodes"]
    verbs: ["get", "list"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard
  namespace: kubernetes-dashboard
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: kubernetes-dashboard
subjects:
  - kind: ServiceAccount
    name: kubernetes-dashboard
    namespace: kubernetes-dashboard
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: kubernetes-dashboard
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: kubernetes-dashboard
subjects:
  - kind: ServiceAccount
    name: kubernetes-dashboard
    namespace: kubernetes-dashboard
---
kind: Deployment
apiVersion: apps/v1
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard
  namespace: kubernetes-dashboard
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      k8s-app: kubernetes-dashboard
  template:
    metadata:
      labels:
        k8s-app: kubernetes-dashboard
    spec:
      containers:
        - name: kubernetes-dashboard
          image: kubernetesui/dashboard:v2.7.0
          imagePullPolicy: Always
          ports:
            - containerPort: 8443
              protocol: TCP
          args:
            - --auto-generate-certificates
            - --namespace=kubernetes-dashboard
          volumeMounts:
            - name: kubernetes-dashboard-certs
              mountPath: /certs
            - mountPath: /tmp
              name: tmp-volume
          livenessProbe:
            httpGet:
              scheme: HTTPS
              path: /
              port: 8443
            initialDelaySeconds: 30
            timeoutSeconds: 30
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsUser: 1001
            runAsGroup: 2001
      volumes:
        - name: kubernetes-dashboard-certs
          secret:
            secretName: kubernetes-dashboard-certs
        - name: tmp-volume
          emptyDir: {}
      serviceAccountName: kubernetes-dashboard
      nodeSelector:
        "kubernetes.io/os": linux
      tolerations:
        - key: node-role.kubernetes.io/master
          effect: NoSchedule
---
kind: Service
apiVersion: v1
metadata:
  labels:
    k8s-app: dashboard-metrics-scraper
  name: dashboard-metrics-scraper
  namespace: kubernetes-dashboard
spec:
  ports:
    - port: 8000
      targetPort: 8000
  selector:
    k8s-app: dashboard-metrics-scraper
---
kind: Deployment
apiVersion: apps/v1
metadata:
  labels:
    k8s-app: dashboard-metrics-scraper
  name: dashboard-metrics-scraper
  namespace: kubernetes-dashboard
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      k8s-app: dashboard-metrics-scraper
  template:
    metadata:
      labels:
        k8s-app: dashboard-metrics-scraper
    spec:
      securityContext:
        seccompProfile:
          type: RuntimeDefault
      containers:
        - name: dashboard-metrics-scraper
          image: kubernetesui/metrics-scraper:v1.0.8
          ports:
            - containerPort: 8000
              protocol: TCP
          livenessProbe:
            httpGet:
              scheme: HTTP
              path: /
              port: 8000
            initialDelaySeconds: 30
            timeoutSeconds: 30
          volumeMounts:
          - mountPath: /tmp
            name: tmp-volume
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsUser: 1001
            runAsGroup: 2001
      serviceAccountName: kubernetes-dashboard
      nodeSelector:
        "kubernetes.io/os": linux
      tolerations:
        - key: node-role.kubernetes.io/master
          effect: NoSchedule
      volumes:
        - name: tmp-volume
          emptyDir: {}
EOF
    }

    # ç­‰å¾… Dashboard å¯åŠ¨
    echo "ç­‰å¾… Dashboard å¯åŠ¨..."
    kubectl wait --for=condition=available --timeout=300s deployment/kubernetes-dashboard -n kubernetes-dashboard || true

    # ä¿®æ”¹æœåŠ¡ç±»å‹ä¸º NodePort
    echo "é…ç½® Dashboard å¤–éƒ¨è®¿é—®..."
    kubectl patch svc kubernetes-dashboard -n kubernetes-dashboard -p '{"spec":{"type":"NodePort","ports":[{"port":443,"targetPort":8443,"nodePort":30443}]}}' 2>/dev/null || true

    # åˆ›å»ºç®¡ç†å‘˜ç”¨æˆ·
    echo "åˆ›å»º Kubernetes Dashboard ç®¡ç†å‘˜ç”¨æˆ·..."
    cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: ServiceAccount
metadata:
  name: admin-user
  namespace: kubernetes-dashboard
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: admin-user
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: admin-user
  namespace: kubernetes-dashboard
---
apiVersion: v1
kind: Secret
metadata:
  name: admin-user-token
  namespace: kubernetes-dashboard
  annotations:
    kubernetes.io/service-account.name: admin-user
type: kubernetes.io/service-account-token
EOF

    # ç­‰å¾… Secret åˆ›å»ºå®Œæˆ
    sleep 5

    # ç”Ÿæˆè®¿é—®ä»¤ç‰Œ
    echo "è·å– Kubernetes Dashboard è®¿é—®ä»¤ç‰Œ..."
    K8S_TOKEN=$(kubectl get secret admin-user-token -n kubernetes-dashboard -o jsonpath='{.data.token}' | base64 -d 2>/dev/null || kubectl -n kubernetes-dashboard create token admin-user 2>/dev/null || echo "Tokenç”Ÿæˆå¤±è´¥")
fi

# å®‰è£… Rancherï¼ˆå¦‚æœé€‰æ‹©ï¼‰
if [ "$INSTALL_RANCHER" = true ]; then
    echo "å®‰è£… Rancher..."
    
    # åˆ›å»º cattle-system å‘½åç©ºé—´
    kubectl create namespace cattle-system 2>/dev/null || true
    
    # åˆ›å»º Rancher ServiceAccount å’Œå¿…è¦æƒé™
    echo "é…ç½® Rancher æƒé™..."
    cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: ServiceAccount
metadata:
  name: rancher
  namespace: cattle-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: rancher
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: rancher
  namespace: cattle-system
EOF
    
    # æ£€æŸ¥ç½‘ç»œæ˜¯å¦å°±ç»ª
    echo "æ£€æŸ¥ç½‘ç»œè¿æ¥..."
    NETWORK_READY=false
    for i in {1..3}; do
        if kubectl run network-test --image=busybox --rm -i --restart=Never -- nslookup kubernetes.default > /dev/null 2>&1; then
            NETWORK_READY=true
            break
        fi
        echo "ç½‘ç»œæ£€æŸ¥ç¬¬ $i æ¬¡å¤±è´¥ï¼Œç­‰å¾…é‡è¯•..."
        sleep 10
    done
    
    if [ "$NETWORK_READY" = false ]; then
        echo "âš ï¸  ç½‘ç»œè¿æ¥å¼‚å¸¸ï¼Œé‡å¯ç½‘ç»œç»„ä»¶..."
        kubectl delete pods -n kube-flannel --all 2>/dev/null || true
        sleep 15
    fi
    
    # éƒ¨ç½² Rancherï¼ˆä½¿ç”¨ç®€åŒ–çš„æœ‰æ•ˆé…ç½®ï¼‰
    echo "éƒ¨ç½² Rancher..."
    cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: rancher
  namespace: cattle-system
  labels:
    app: rancher
spec:
  replicas: 1
  selector:
    matchLabels:
      app: rancher
  template:
    metadata:
      labels:
        app: rancher
    spec:
      serviceAccountName: rancher
      hostNetwork: true
      containers:
      - name: rancher
        image: rancher/rancher:v2.7.9
        ports:
        - containerPort: 80
        - containerPort: 443
        env:
        - name: CATTLE_BOOTSTRAP_PASSWORD
          value: "admin123456"
        args:
        - "--add-local=true"
        - "--no-cacerts=true"
        resources:
          requests:
            cpu: "200m"
            memory: "512Mi"
          limits:
            cpu: "1"
            memory: "2Gi"
---
apiVersion: v1
kind: Service
metadata:
  name: rancher
  namespace: cattle-system
  labels:
    app: rancher
spec:
  type: NodePort
  ports:
  - name: http
    port: 80
    targetPort: 80
    nodePort: 30080
  - name: https
    port: 443
    targetPort: 443
    nodePort: 30444
  selector:
    app: rancher
EOF
    
    # ç­‰å¾… Rancher å¯åŠ¨ï¼ˆæ™ºèƒ½ç­‰å¾…ï¼‰
    echo "ç­‰å¾… Rancher å¯åŠ¨..."
    echo "è¿™å¯èƒ½éœ€è¦ 2-3 åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…..."
    
    # ç­‰å¾… Pod å°±ç»ª
    for i in {1..12}; do
        RANCHER_STATUS=$(kubectl get pods -n cattle-system -l app=rancher --no-headers 2>/dev/null | awk '{print $3}' | head -1)
        if [ "$RANCHER_STATUS" = "Running" ]; then
            echo "âœ… Rancher å¯åŠ¨æˆåŠŸï¼"
            break
        elif [ "$RANCHER_STATUS" = "CrashLoopBackOff" ] || [ "$RANCHER_STATUS" = "Error" ]; then
            echo "âš ï¸  Rancher å¯åŠ¨å¤±è´¥ï¼ŒçŠ¶æ€: $RANCHER_STATUS"
            echo "æ£€æŸ¥æ—¥å¿—ï¼š"
            kubectl logs -n cattle-system -l app=rancher --tail=10 2>/dev/null || echo "æ—¥å¿—æš‚ä¸å¯ç”¨"
            break
        else
            echo "ç­‰å¾…ä¸­... (${i}/12) å½“å‰çŠ¶æ€: ${RANCHER_STATUS:-"åˆ›å»ºä¸­"}"
            sleep 15
        fi
    done
    
    # æœ€ç»ˆçŠ¶æ€æ£€æŸ¥
    FINAL_STATUS=$(kubectl get pods -n cattle-system -l app=rancher --no-headers 2>/dev/null | awk '{print $3}' | head -1)
    if [ "$FINAL_STATUS" = "Running" ]; then
        echo "ğŸ‰ Rancher éƒ¨ç½²æˆåŠŸï¼"
    else
        echo "âš ï¸  Rancher å½“å‰çŠ¶æ€: $FINAL_STATUS"
        echo "å¯ä»¥è¿è¡Œä»¥ä¸‹å‘½ä»¤æ£€æŸ¥ï¼š"
        echo "kubectl get pods -n cattle-system"
        echo "kubectl logs -n cattle-system deployment/rancher -f"
    fi
fi

echo ""
echo "ğŸ”§ [13/13] é…ç½®å®Œæˆ..."

echo ""
echo "ğŸ‰ Kubernetes é›†ç¾¤å®‰è£…å®Œæˆï¼"
echo "================================================================"

# æ˜¾ç¤ºé›†ç¾¤çŠ¶æ€
echo "é›†ç¾¤èŠ‚ç‚¹çŠ¶æ€:"
kubectl get nodes -o wide

echo ""
echo "ç³»ç»Ÿ Pods çŠ¶æ€:"
kubectl get pods -n kube-system

if [ "$INSTALL_K8S_DASHBOARD" = true ]; then
    echo ""
    echo "Kubernetes Dashboard Pods:"
    kubectl get pods -n kubernetes-dashboard
fi

if [ "$INSTALL_RANCHER" = true ]; then
    echo ""
    echo "Rancher Pods:"
    kubectl get pods -n cattle-system
fi

if [ "$INSTALL_KUBESPHERE" = true ]; then
    echo ""
    echo "KubeSphere Pods:"
    kubectl get pods -n kubesphere-system
fi

echo ""
echo "================================================================"
echo "ğŸ”‘ Worker èŠ‚ç‚¹åŠ å…¥å‘½ä»¤ï¼š"
kubeadm token create --print-join-command
echo "================================================================"

echo ""
echo "ğŸ“Š æ§åˆ¶å°è®¿é—®ä¿¡æ¯ï¼š"

if [ "$INSTALL_K8S_DASHBOARD" = true ]; then
    echo ""
    echo "ğŸ¯ Kubernetes Dashboard:"
    echo "åœ°å€: https://$LOCAL_IP:30443"
    echo "ç™»å½•æ–¹å¼: Token"
    echo "è®¿é—®ä»¤ç‰Œ:"
    echo "$K8S_TOKEN"
fi

if [ "$INSTALL_RANCHER" = true ]; then
    echo ""
    echo "ğŸ¯ Rancher æ§åˆ¶å°:"
    echo "åœ°å€: https://$LOCAL_IP:30444"
    echo "å¤‡ç”¨åœ°å€: http://$LOCAL_IP:30080"
    echo "åˆå§‹ç”¨æˆ·å: admin"
    echo "åˆå§‹å¯†ç : admin123456"
    echo "âš ï¸  é¦–æ¬¡ç™»å½•åè¯·è®¾ç½®æ–°å¯†ç "
fi

if [ "$INSTALL_KUBESPHERE" = true ]; then
    echo ""
    echo "ğŸ¯ KubeSphere æ§åˆ¶å°:"
    echo "åœ°å€: http://$LOCAL_IP:30880"
    echo "é»˜è®¤ç”¨æˆ·å: admin"
    echo "é»˜è®¤å¯†ç : P@88w0rd"
    echo "âš ï¸  é¦–æ¬¡ç™»å½•åè¯·åŠæ—¶ä¿®æ”¹é»˜è®¤å¯†ç "
    echo "ğŸ’¡ KubeSphere æ”¯æŒå®Œæ•´çš„ç”¨æˆ·ç®¡ç†å’Œä¸­æ–‡ç•Œé¢"
fi

echo ""
echo "ğŸ” ç›‘æ§å‘½ä»¤ï¼š"
echo "kubectl get pods --all-namespaces                              # æŸ¥çœ‹æ‰€æœ‰ Pod"

if [ "$INSTALL_K8S_DASHBOARD" = true ]; then
    echo "kubectl get svc -n kubernetes-dashboard                        # æŸ¥çœ‹ Dashboard æœåŠ¡"
    echo "kubectl -n kubernetes-dashboard create token admin-user        # é‡æ–°ç”Ÿæˆ Dashboard ä»¤ç‰Œ"
fi

if [ "$INSTALL_RANCHER" = true ]; then
    echo "kubectl get svc -n cattle-system                               # æŸ¥çœ‹ Rancher æœåŠ¡"
    echo "kubectl logs -n cattle-system deployment/rancher -f            # æŸ¥çœ‹ Rancher æ—¥å¿—"
fi

echo "systemctl status kubelet                                       # kubelet çŠ¶æ€"
echo "systemctl status containerd                                    # containerd çŠ¶æ€"
echo "crictl ps                                                      # å®¹å™¨åˆ—è¡¨"

echo ""
echo "âš ï¸  é‡è¦æé†’ï¼š"
echo "1. æ§åˆ¶å°ä½¿ç”¨ HTTPSï¼Œæµè§ˆå™¨ä¼šæç¤ºè¯ä¹¦è­¦å‘Šï¼Œç‚¹å‡»'é«˜çº§'->'ç»§ç»­è®¿é—®'å³å¯"

if [ "$INSTALL_K8S_DASHBOARD" = true ]; then
    echo "2. Kubernetes Dashboard ä½¿ç”¨ Token ç™»å½•ï¼Œå®‰å…¨æ€§æ›´é«˜"
fi

if [ "$INSTALL_RANCHER" = true ]; then
    echo "3. Rancher æ”¯æŒå›¾å½¢åŒ–ç”¨æˆ·ç®¡ç†ï¼Œå¯ä»¥åœ¨ç•Œé¢ç›´æ¥æ·»åŠ ç”¨æˆ·"
    echo "4. Rancher å®Œå…¨å¯åŠ¨éœ€è¦ 5-10 åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…"
fi

echo "5. å¦‚æœæ˜¯äº‘æœåŠ¡å™¨ï¼Œè¯·ç¡®ä¿é˜²ç«å¢™å¼€æ”¾ä»¥ä¸‹ç«¯å£ï¼š"
echo "   - 6443 (Kubernetes API)"
echo "   - 30000-32767 (NodePort æœåŠ¡)"

if [ "$INSTALL_K8S_DASHBOARD" = true ]; then
    echo "   - 30443 (Kubernetes Dashboard)"
fi

if [ "$INSTALL_RANCHER" = true ]; then
    echo "   - 30080 (Rancher HTTP)"
    echo "   - 30444 (Rancher HTTPS)"
fi

echo ""
echo "ğŸŒ ç½‘ç»œæ•…éšœæ’é™¤ï¼š"
echo "å¦‚æœç½‘ç»œæœ‰é—®é¢˜ï¼Œå¯ä»¥è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š"
echo "kubectl get pods -n kube-flannel                               # æ£€æŸ¥ Flannel çŠ¶æ€"
echo "ls -la /run/flannel/                                           # æ£€æŸ¥ Flannel é…ç½®æ–‡ä»¶"
echo "kubectl logs -n kube-flannel -l app=flannel                    # æŸ¥çœ‹ Flannel æ—¥å¿—"
echo "kubectl describe pod [dashboard-pod-name] -n kubernetes-dashboard  # æŸ¥çœ‹ Dashboard Pod è¯¦æƒ…"

echo ""
echo "âœ… è„šæœ¬æ‰§è¡Œå®Œæ¯•ï¼é›†ç¾¤å’Œæ§åˆ¶å°å·²å‡†å¤‡å°±ç»ªã€‚"
